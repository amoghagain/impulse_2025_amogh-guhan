{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10505254,"sourceType":"datasetVersion","datasetId":6503469},{"sourceId":10505265,"sourceType":"datasetVersion","datasetId":6503475},{"sourceId":10507624,"sourceType":"datasetVersion","datasetId":6505151},{"sourceId":10507862,"sourceType":"datasetVersion","datasetId":6505306},{"sourceId":10508503,"sourceType":"datasetVersion","datasetId":6505778}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-19T11:28:39.609837Z","iopub.execute_input":"2025-01-19T11:28:39.610192Z","iopub.status.idle":"2025-01-19T11:28:39.956872Z","shell.execute_reply.started":"2025-01-19T11:28:39.610163Z","shell.execute_reply":"2025-01-19T11:28:39.956199Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"from scipy.signal import butter, filtfilt, iirnotch, savgol_filter, medfilt\nimport numpy as np\nimport pandas as pd\nimport os\nimport pywt\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom pathlib import Path\nimport argparse\n\ndef design_filters():\n    \"\"\"\n    Design specialized filters for EEG signal processing\n    \"\"\"\n    def notch_filter(signal, fs=250):\n        # Power line interference (50/60 Hz)\n        f0 = 50.0  # Notch frequency\n        Q = 30.0  # Quality factor\n        w0 = f0/(fs/2)\n        b, a = iirnotch(w0, Q)\n        return filtfilt(b, a, signal)\n    \n    def eeg_bandpass(signal, fs=250):\n        # EEG-specific bandpass (0.5-45 Hz to preserve relevant brain activity)\n        nyquist = fs/2\n        b, a = butter(4, [0.5/nyquist, 45/nyquist], btype='band')\n        return filtfilt(b, a, signal)\n    \n    return notch_filter, eeg_bandpass\n\ndef wavelet_denoising(signal, wavelet='db4'):\n    \"\"\"\n    Advanced wavelet denoising specifically tuned for EEG\n    \"\"\"\n    # Decompose signal\n    coeffs = pywt.wavedec(signal, wavelet, level=4)\n    \n    # Keep approximation coefficients unchanged\n    # and apply progressive thresholding to detail coefficients\n    for i in range(1, len(coeffs)):\n        # Universal threshold with level-dependent sigma estimation\n        sigma = np.median(np.abs(coeffs[i])) / 0.6745\n        threshold = sigma * np.sqrt(2 * np.log(len(coeffs[i])))\n        # Softer thresholding for lower frequency components\n        threshold *= (1 - (i / len(coeffs)))\n        coeffs[i] = pywt.threshold(coeffs[i], threshold, mode='garrote')\n    \n    return pywt.waverec(coeffs, wavelet)\n\ndef baseline_correction(signal, window_size=1000):\n    \"\"\"\n    Remove baseline wandering using moving average\n    \"\"\"\n    # Ensure window size is odd\n    window_size = window_size + 1 if window_size % 2 == 0 else window_size\n    \n    # Compute moving average for baseline estimation\n    padding = np.ones(window_size//2)\n    padded_signal = np.concatenate([padding * signal[0], signal, padding * signal[-1]])\n    baseline = np.convolve(padded_signal, np.ones(window_size)/window_size, mode='valid')\n    \n    return signal - baseline\n\ndef denoise_eeg(signal):\n    \"\"\"\n    Enhanced EEG denoising pipeline\n    \"\"\"\n    # Get filter functions\n    notch_filter, eeg_bandpass = design_filters()\n    \n    # Step 1: Remove baseline wandering\n    signal_baselined = baseline_correction(signal)\n    \n    # Step 2: Apply notch filter for power line interference\n    signal_notched = notch_filter(signal_baselined)\n    \n    # Step 3: Apply EEG-specific bandpass filter\n    signal_filtered = eeg_bandpass(signal_notched)\n    \n    # Step 4: Apply wavelet denoising\n    signal_denoised = wavelet_denoising(signal_filtered)\n    \n    return signal_denoised\n\ndef plot_comparison(noisy_data, denoised_data, title=\"Signal Comparison\", save_path=None):\n    \"\"\"\n    Plot comparison between noisy and denoised signals\n    \"\"\"\n    plt.figure(figsize=(15, 8))\n    \n    # Plot first channel as example\n    time = np.arange(noisy_data.shape[1]) / 250  # Assuming 250 Hz sampling rate\n    \n    plt.subplot(2, 1, 1)\n    plt.plot(time, noisy_data[0], label='Noisy', alpha=0.7)\n    plt.title(f'{title} - Noisy Signal')\n    plt.xlabel('Time (s)')\n    plt.ylabel('Amplitude')\n    plt.grid(True)\n    plt.legend()\n    \n    plt.subplot(2, 1, 2)\n    plt.plot(time, denoised_data[0], label='Denoised', alpha=0.7)\n    plt.title('Denoised Signal')\n    plt.xlabel('Time (s)')\n    plt.ylabel('Amplitude')\n    plt.grid(True)\n    plt.legend()\n    \n    plt.tight_layout()\n    \n    if save_path:\n        plt.savefig(save_path)\n        plt.close()\n    else:\n        plt.show()\n\ndef calculate_psnr(clean, denoised):\n    \"\"\"\n    Calculate PSNR with robust normalization\n    \"\"\"\n    # Normalize both signals to same scale\n    clean = (clean - np.mean(clean)) / (np.std(clean) + 1e-10)\n    denoised = (denoised - np.mean(denoised)) / (np.std(denoised) + 1e-10)\n    \n    mse = np.mean((clean - denoised) ** 2)\n    if mse < 1e-10:\n        return 100.0\n    \n    # Use fixed reference value for max signal after normalization\n    max_signal = 3.0  # 3 sigma range\n    return 20 * np.log10(max_signal / np.sqrt(mse))\n\ndef process_and_save_data(noisy_data_path, output_path, plot_dir=None):\n    \"\"\"\n    Process and save denoised EEG data\n    \"\"\"\n    noisy_data_path = Path(noisy_data_path)\n    output_path = Path(output_path)\n    output_path.mkdir(parents=True, exist_ok=True)\n    \n    if plot_dir:\n        plot_dir = Path(plot_dir)\n        plot_dir.mkdir(parents=True, exist_ok=True)\n    \n    class_folders = [f for f in noisy_data_path.iterdir() if f.is_dir()]\n    \n    results = []\n    for class_folder in class_folders:\n        print(f\"\\nProcessing {class_folder.name}\")\n        \n        class_output_path = output_path / class_folder.name\n        class_output_path.mkdir(exist_ok=True)\n        \n        files = list(class_folder.glob('*.npy'))\n        \n        for file_path in tqdm(files, desc=f\"Denoising {class_folder.name}\"):\n            noisy_data = np.load(file_path)\n            \n            denoised_data = np.zeros_like(noisy_data)\n            for ch in range(noisy_data.shape[0]):\n                denoised_data[ch] = denoise_eeg(noisy_data[ch])\n            \n            output_file = class_output_path / f\"denoised_{file_path.name}\"\n            np.save(output_file, denoised_data)\n            \n            if plot_dir and file_path == files[0]:\n                plot_path = plot_dir / f\"{class_folder.name}_comparison.png\"\n                plot_comparison(noisy_data, denoised_data, \n                              title=f\"{class_folder.name} - {file_path.name}\",\n                              save_path=plot_path)\n            \n            results.append({\n                'class': class_folder.name,\n                'file': file_path.name,\n                'original_path': str(file_path),\n                'denoised_path': str(output_file)\n            })\n    \n    # Save processing summary\n    df = pd.DataFrame(results)\n    df.to_csv(output_path / 'processing_summary.csv', index=False)\n    return df\n\ndef calculate_psnr_metrics(denoised_path, clean_path):\n    \"\"\"\n    Calculate PSNR metrics between denoised and clean data\n    \"\"\"\n    denoised_path = Path(denoised_path)\n    clean_path = Path(clean_path)\n    \n    results = []\n    class_folders = [f for f in denoised_path.iterdir() if f.is_dir()]\n    \n    for class_folder in class_folders:\n        print(f\"\\nProcessing {class_folder.name}\")\n        clean_class_path = clean_path / class_folder.name\n        \n        if not clean_class_path.exists():\n            print(f\"Warning: Clean data folder not found for {class_folder.name}\")\n            continue\n        \n        denoised_files = list(class_folder.glob('denoised_*.npy'))\n        \n        for denoised_file in tqdm(denoised_files, desc=f\"Calculating PSNR for {class_folder.name}\"):\n            clean_file = clean_class_path / denoised_file.name.replace('denoised_', '')\n            \n            if not clean_file.exists():\n                print(f\"Warning: Clean file not found for {denoised_file.name}\")\n                continue\n                \n            denoised_data = np.load(denoised_file)\n            clean_data = np.load(clean_file)\n            \n            channel_psnrs = []\n            for ch in range(clean_data.shape[0]):\n                psnr = calculate_psnr(clean_data[ch], denoised_data[ch])\n                channel_psnrs.append(psnr)\n            \n            results.append({\n                'class': class_folder.name,\n                'file': denoised_file.name,\n                'avg_psnr': np.mean(channel_psnrs),\n                'min_psnr': np.min(channel_psnrs),\n                'max_psnr': np.max(channel_psnrs),\n                'std_psnr': np.std(channel_psnrs)\n            })\n    \n    df = pd.DataFrame(results)\n    print(\"\\nPSNR Summary Statistics:\")\n    print(df.describe())\n    \n    # Save results\n    results_path = denoised_path / 'psnr_results.csv'\n    df.to_csv(results_path, index=False)\n    print(f\"\\nDetailed results saved to: {results_path}\")\n    \n    return df\n\ndef main():\n    parser = argparse.ArgumentParser(description='EEG Signal Denoising Pipeline')\n    parser.add_argument('--input_dir', type=str, required=True,\n                        help='Directory containing noisy EEG data')\n    parser.add_argument('--output_dir', type=str, required=True,\n                        help='Directory to save denoised data')\n    parser.add_argument('--clean_dir', type=str,\n                        help='Optional: Directory containing clean data for PSNR evaluation')\n    parser.add_argument('--plot_dir', type=str,\n                        help='Optional: Directory to save comparison plots')\n    \n    args = parser.parse_args()\n    \n    # Step 1: Process and save denoised data\n    print(\"Step 1: Processing and saving denoised data...\")\n    process_summary = process_and_save_data(args.input_dir, args.output_dir, args.plot_dir)\n    \n    # Step 2: Calculate PSNR if clean data is provided\n    if args.clean_dir:\n        print(\"\\nStep 2: Calculating PSNR metrics...\")\n        psnr_results = calculate_psnr_metrics(args.output_dir, args.clean_dir)\n    \n    print(\"\\nProcessing completed successfully!\")\n\nif __name__ == \"__main__\":\n    # Example usage with hardcoded paths\n    noisy_data_path = \"/kaggle/input/eeg-datas/EEG_Data/noisy_train_data\"\n    clean_data_path = \"/kaggle/input/eeg-datas/EEG_Data/train_data\"\n    denoised_output_path = \"denoised_data\"\n    plot_output_path = \"comparison_plots\"\n    \n    # You can either use the command line interface:\n    # main()\n    \n    # Or call the functions directly:\n    print(\"Step 1: Processing and saving denoised data...\")\n    process_summary = process_and_save_data(noisy_data_path, denoised_output_path, plot_output_path)\n    \n    print(\"\\nStep 2: Calculating PSNR metrics...\")\n    psnr_results = calculate_psnr_metrics(denoised_output_path, clean_data_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T11:28:39.957937Z","iopub.execute_input":"2025-01-19T11:28:39.958329Z","iopub.status.idle":"2025-01-19T11:32:14.854934Z","shell.execute_reply.started":"2025-01-19T11:28:39.958306Z","shell.execute_reply":"2025-01-19T11:32:14.854148Z"}},"outputs":[{"name":"stdout","text":"Step 1: Processing and saving denoised data...\n\nProcessing Complex_Partial_Seizures\n","output_type":"stream"},{"name":"stderr","text":"Denoising Complex_Partial_Seizures: 100%|██████████| 2196/2196 [01:09<00:00, 31.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nProcessing Normal\n","output_type":"stream"},{"name":"stderr","text":"Denoising Normal: 100%|██████████| 2783/2783 [01:25<00:00, 32.47it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nProcessing Video_detected_Seizures_with_no_visual_change_over_EEG\n","output_type":"stream"},{"name":"stderr","text":"Denoising Video_detected_Seizures_with_no_visual_change_over_EEG: 100%|██████████| 84/84 [00:03<00:00, 27.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nProcessing Electrographic_Seizures\n","output_type":"stream"},{"name":"stderr","text":"Denoising Electrographic_Seizures: 100%|██████████| 545/545 [00:17<00:00, 31.99it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nStep 2: Calculating PSNR metrics...\n\nProcessing Video_detected_Seizures_with_no_visual_change_over_EEG\n","output_type":"stream"},{"name":"stderr","text":"Calculating PSNR for Video_detected_Seizures_with_no_visual_change_over_EEG: 100%|██████████| 84/84 [00:00<00:00, 143.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nProcessing Normal\n","output_type":"stream"},{"name":"stderr","text":"Calculating PSNR for Normal: 100%|██████████| 2783/2783 [00:18<00:00, 146.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nProcessing Electrographic_Seizures\n","output_type":"stream"},{"name":"stderr","text":"Calculating PSNR for Electrographic_Seizures: 100%|██████████| 545/545 [00:03<00:00, 144.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nProcessing Complex_Partial_Seizures\n","output_type":"stream"},{"name":"stderr","text":"Calculating PSNR for Complex_Partial_Seizures: 100%|██████████| 2196/2196 [00:15<00:00, 143.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nPSNR Summary Statistics:\n          avg_psnr     min_psnr     max_psnr     std_psnr\ncount  5608.000000  5608.000000  5608.000000  5608.000000\nmean      8.656671     5.999589    12.228704     1.627040\nstd       1.411280     0.819848     3.030967     0.659654\nmin       6.264783     3.848330     7.409066     0.307319\n25%       7.587193     5.434902    10.098515     1.145749\n50%       8.377553     5.918633    11.603919     1.521642\n75%       9.336047     6.445319    13.576932     1.962726\nmax      15.282770    10.176529    29.743308     4.838150\n\nDetailed results saved to: denoised_data/psnr_results.csv\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import classification_report\nimport xgboost as xgb\nfrom pathlib import Path\nfrom tqdm import tqdm\nimport pywt\nfrom scipy import signal\nfrom scipy.stats import kurtosis, skew\n\nclass KaggleEEGClassifier:\n    def __init__(self, sampling_rate=256):\n        self.sampling_rate = sampling_rate\n        self.frequency_bands = {\n            'delta': (0.5, 4),\n            'theta': (4, 8),\n            'alpha': (8, 13),\n            'beta': (13, 30),\n            'gamma': (30, 80)\n        }\n        \n    def extract_features(self, signal_data):\n        \"\"\"Extract key EEG features from signal\"\"\"\n        features = {}\n        \n        # Time domain features\n        features.update({\n            'mean': np.mean(signal_data),\n            'std': np.std(signal_data),\n            'kurtosis': kurtosis(signal_data),\n            'skewness': skew(signal_data),\n            'peak_to_peak': np.max(signal_data) - np.min(signal_data),\n            'zero_crossings': np.sum(np.diff(np.signbit(signal_data)).astype(int)),\n            'line_length': np.sum(np.abs(np.diff(signal_data)))\n        })\n        \n        # Frequency domain features\n        freqs, psd = signal.welch(signal_data, self.sampling_rate, nperseg=min(256, len(signal_data)))\n        total_power = np.sum(psd)\n        \n        for band_name, (low, high) in self.frequency_bands.items():\n            mask = (freqs >= low) & (freqs <= high)\n            band_power = np.sum(psd[mask])\n            features[f'{band_name}_power'] = band_power\n            features[f'{band_name}_ratio'] = band_power / total_power if total_power > 0 else 0\n        \n        # Wavelet features\n        coeffs = pywt.wavedec(signal_data, 'db4', level=4)\n        for i, coeff in enumerate(coeffs):\n            features[f'wavelet_l{i}_energy'] = np.sum(coeff**2)\n            features[f'wavelet_l{i}_mean'] = np.mean(np.abs(coeff))\n        \n        return features\n\n    def prepare_data(self, denoised_data_path):\n        \"\"\"Process EEG data and extract features\"\"\"\n        features_list = []\n        labels = []\n        \n        denoised_path = Path(denoised_data_path)\n        \n        for class_folder in denoised_path.iterdir():\n            if not class_folder.is_dir():\n                continue\n                \n            print(f\"Processing {class_folder.name}\")\n            files = list(class_folder.glob('denoised_*.npy'))\n            \n            for file_path in tqdm(files):\n                try:\n                    signal_data = np.load(file_path)\n                    \n                    if np.any(np.isnan(signal_data)):\n                        continue\n                    \n                    # Process each channel\n                    file_features = {}\n                    for ch in range(signal_data.shape[0]):\n                        channel_features = self.extract_features(signal_data[ch])\n                        for key, value in channel_features.items():\n                            file_features[f'ch{ch}_{key}'] = value\n                    \n                    # Add cross-channel features\n                    for i in range(signal_data.shape[0]):\n                        for j in range(i+1, signal_data.shape[0]):\n                            correlation = np.corrcoef(signal_data[i], signal_data[j])[0,1]\n                            file_features[f'correlation_ch{i}_ch{j}'] = correlation\n                    \n                    features_list.append(file_features)\n                    labels.append(class_folder.name)\n                    \n                except Exception as e:\n                    print(f\"Error processing {file_path}: {str(e)}\")\n                    continue\n        \n        return pd.DataFrame(features_list), labels\n\ndef train_classifier(X, y, random_state=42):\n    \"\"\"Train and evaluate the XGBoost classifier\"\"\"\n    # Prepare data\n    le = LabelEncoder()\n    y_encoded = le.fit_transform(y)\n    \n    # Initialize model\n    model = xgb.XGBClassifier(\n        n_estimators=200,\n        max_depth=7,\n        learning_rate=0.1,\n        subsample=0.8,\n        colsample_bytree=0.8,\n        random_state=random_state,\n        tree_method='hist',  # Faster training\n        objective='multi:softprob',\n        eval_metric='mlogloss'\n    )\n    \n    # Create cross-validation folds\n    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)\n    \n    # Train and evaluate\n    scores = []\n    for fold, (train_idx, val_idx) in enumerate(cv.split(X, y_encoded), 1):\n        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n        y_train, y_val = y_encoded[train_idx], y_encoded[val_idx]\n        \n        # Scale features\n        scaler = StandardScaler()\n        X_train_scaled = scaler.fit_transform(X_train)\n        X_val_scaled = scaler.transform(X_val)\n        \n        # Train model\n        model.fit(X_train_scaled, y_train,\n                 eval_set=[(X_val_scaled, y_val)],\n                 early_stopping_rounds=20,\n                 verbose=0)\n        \n        # Evaluate\n        y_pred = model.predict(X_val_scaled)\n        score = classification_report(y_val, y_pred, output_dict=True)\n        scores.append(score['weighted avg']['f1-score'])\n        \n        print(f\"Fold {fold} F1-Score: {scores[-1]:.4f}\")\n    \n    print(f\"\\nMean F1-Score: {np.mean(scores):.4f} (+/- {np.std(scores):.4f})\")\n    \n    # Train final model on full dataset\n    X_scaled = scaler.fit_transform(X)\n    model.fit(X_scaled, y_encoded)\n    \n    return model, scaler, le\n\ndef main():\n    # Set paths\n    DATA_PATH = \"/kaggle/working/denoised_data\"  # Adjust path as needed\n    \n    # Initialize classifier\n    classifier = KaggleEEGClassifier()\n    \n    # Prepare data\n    print(\"Preparing dataset...\")\n    X, y = classifier.prepare_data(DATA_PATH)\n    \n    print(\"\\nDataset Summary:\")\n    print(f\"Total samples: {len(X)}\")\n    print(f\"Features: {X.shape[1]}\")\n    print(\"\\nClass distribution:\")\n    for label, count in pd.Series(y).value_counts().items():\n        print(f\"{label}: {count}\")\n    \n    # Train and evaluate\n    print(\"\\nTraining classifier...\")\n    model, scaler, label_encoder = train_classifier(X, y)\n    \n    # Save model and transformers\n    model.save_model('eeg_model.json')\n    \n    return model, scaler, label_encoder\n\nif __name__ == \"__main__\":\n    model, scaler, label_encoder = main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T11:36:05.948126Z","iopub.execute_input":"2025-01-19T11:36:05.948443Z","iopub.status.idle":"2025-01-19T11:42:58.487895Z","shell.execute_reply.started":"2025-01-19T11:36:05.948418Z","shell.execute_reply":"2025-01-19T11:42:58.485539Z"}},"outputs":[{"name":"stdout","text":"Preparing dataset...\nProcessing Video_detected_Seizures_with_no_visual_change_over_EEG\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 84/84 [00:04<00:00, 20.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing Normal\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2783/2783 [02:21<00:00, 19.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing Electrographic_Seizures\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 545/545 [00:27<00:00, 19.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing Complex_Partial_Seizures\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2196/2196 [01:54<00:00, 19.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nDataset Summary:\nTotal samples: 5608\nFeatures: 684\n\nClass distribution:\nNormal: 2783\nComplex_Partial_Seizures: 2196\nElectrographic_Seizures: 545\nVideo_detected_Seizures_with_no_visual_change_over_EEG: 84\n\nTraining classifier...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Fold 1 F1-Score: 0.7738\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Fold 2 F1-Score: 0.7467\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-5d97fd0eaed1>\u001b[0m in \u001b[0;36m<cell line: 181>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-5-5d97fd0eaed1>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;31m# Train and evaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nTraining classifier...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;31m# Save model and transformers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-5d97fd0eaed1>\u001b[0m in \u001b[0;36mtrain_classifier\u001b[0;34m(X, y, random_state)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;31m# Train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         model.fit(X_train_scaled, y_train,\n\u001b[0m\u001b[1;32m    135\u001b[0m                  \u001b[0meval_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                  \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1517\u001b[0m             )\n\u001b[1;32m   1518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1519\u001b[0;31m             self._Booster = train(\n\u001b[0m\u001b[1;32m   1520\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1521\u001b[0m                 \u001b[0mtrain_dmatrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   2049\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2050\u001b[0m             _check_call(\n\u001b[0;32m-> 2051\u001b[0;31m                 _LIB.XGBoosterUpdateOneIter(\n\u001b[0m\u001b[1;32m   2052\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2053\u001b[0m                 )\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":5},{"cell_type":"code","source":"from scipy.fft import fft, fftfreq\n\ndef fourier_transform(signals, sampling_rate):\n    \"\"\"\n    Perform Fourier Transform on the given signal.\n    \"\"\"\n    for signal in signals:\n        fft_result = np.abs(fft(signal)) # Get rid of imaginary values\n        frequencies = fftfreq(len(signal), 1 / sampling_rate)  # Frequency bins\n        fft_magnitudes = fft_result[:len(fft_result)//2]\n        frequencies = frequencies[:len(frequencies)//2]\n        \n    return fft_magnitudes, frequencies\n\nfrom scipy.signal import find_peaks\n\ndef extract_channel_features(i, signal, sampling_rate):\n    \"\"\"Extract specified features for a single channel.\"\"\"\n    # FFT computation\n    fft_result, frequencies = fourier_transform([signal], sampling_rate)\n    \n    # Keep only positive frequencies\n    positive_frequencies = frequencies > 0\n    fft_result = fft_result[positive_frequencies]\n    frequencies = frequencies[positive_frequencies]\n    \n    # Dominant frequency and amplitude\n    dominant_idx = np.argmax(fft_result)\n    dominant_frequency = frequencies[dominant_idx]\n    dominant_amplitude = fft_result[dominant_idx]\n    \n    # Total power\n    total_power = np.sum(fft_result**2)/len(fft_result)\n    \n    # Spectral centroid\n    spectral_centroid = np.sum(frequencies * fft_result) / np.sum(fft_result)\n    \n    # Spectral bandwidth\n    spectral_bandwidth = np.sqrt(np.sum(((frequencies - spectral_centroid)**2) * fft_result) / np.sum(fft_result))\n    \n    # Shannon entropy\n    spectral_prob = fft_result / np.sum(fft_result)\n    spectral_entropy = -np.sum(spectral_prob * np.log2(spectral_prob + 1e-12))  # Adding a small value for numerical stability\n    \n    # Frequency variance\n    frequency_variance = np.var(fft_result)\n    \n    # Zero-crossing rate (ZCR) of the original signal\n    zcr = np.sum(np.sign(np.diff(signal)) != 0)/len(signal)\n\n    return {\n        \"Channel\":i,\n        \"Dominant_Frequency\": dominant_frequency,\n        \"Dominant_Amplitude\": dominant_amplitude,\n        \"Total_Power\": total_power,\n        \"Spectral_Centroid\": spectral_centroid,\n        \"Spectral_Bandwidth\": spectral_bandwidth,\n        \"Spectral_Entropy\": spectral_entropy,\n        \"Frequency_Variance\": frequency_variance,\n        \"Zero_Crossing_Rate\": zcr\n    }\n\ndef signal_features(signals, sampling_rate):\n    features = []\n    for i in range(len(signals)):\n        signal = signals[i]\n        features.append(extract_channel_features(i+1, signal, sampling_rate))\n    return pd.DataFrame(features)\n\ndef flatten_features(features_df):\n    flattened_features = {}\n    for column in features_df.columns:\n        if column != \"Channel\":  # Skip the Channel column as it's used for indexing\n            for idx, value in enumerate(features_df[column]):\n                key = f\"{column}_Ch{idx + 1}\"\n                flattened_features[key] = value\n    \n    return pd.DataFrame([flattened_features])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T11:44:16.283919Z","iopub.execute_input":"2025-01-19T11:44:16.284315Z","iopub.status.idle":"2025-01-19T11:44:16.294277Z","shell.execute_reply.started":"2025-01-19T11:44:16.284283Z","shell.execute_reply":"2025-01-19T11:44:16.293311Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Get .npy files from a class folder and make a dataframe containing its Fourier features\ndef features_from_folder(folder_path, sampling_rate):\n\n    all_features = []\n\n    for filename in os.listdir(folder_path):\n        if filename.endswith(\".npy\"):  \n            file_path = os.path.join(folder_path, filename)\n            signals = np.load(file_path) \n                \n            sig = signal_features(signals, sampling_rate)\n            flat = flatten_features(sig)\n            all_features.append(flat)\n    \n    features_df = pd.concat(all_features,ignore_index=True)\n    \n    return features_df\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T11:44:17.139781Z","iopub.execute_input":"2025-01-19T11:44:17.140236Z","iopub.status.idle":"2025-01-19T11:44:17.147023Z","shell.execute_reply.started":"2025-01-19T11:44:17.140197Z","shell.execute_reply":"2025-01-19T11:44:17.146003Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Validation Data\n\ncps_df = features_from_folder(\"/kaggle/input/eeg-datas/EEG_Data/validation_data/Complex_Partial_Seizures\", 1000)\ncps_df[\"Label\"] = 1\nnormal_df = features_from_folder(\"/kaggle/input/eeg-datas/EEG_Data/validation_data/Normal\", 1000)\nnormal_df[\"Label\"] = 0\nes_df = features_from_folder(\"/kaggle/input/eeg-datas/EEG_Data/validation_data/Electrographic_Seizures\", 1000)\nes_df[\"Label\"] = 2\nvds_df = features_from_folder(\"/kaggle/input/eeg-datas/EEG_Data/validation_data/Video_detected_Seizures_with_no_visual_change_over_EEG\", 1000)\nvds_df[\"Label\"] = 3\n\nval_data = pd.concat([cps_df, normal_df, es_df, vds_df], ignore_index=True)\nval_data = val_data.sample(frac=1).reset_index(drop=True)\nX_val = val_data.drop(\"Label\", axis=1)\ny_val = val_data[\"Label\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T11:44:19.501161Z","iopub.execute_input":"2025-01-19T11:44:19.501485Z","iopub.status.idle":"2025-01-19T11:44:36.383756Z","shell.execute_reply.started":"2025-01-19T11:44:19.501463Z","shell.execute_reply":"2025-01-19T11:44:36.382648Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Denoised Data\n\ncps_den_df = features_from_folder(\"/kaggle/working/denoised_data/Complex_Partial_Seizures\", 1000)\ncps_den_df[\"Label\"] = 1\nnormal_den_df = features_from_folder(\"/kaggle/working/denoised_data/Normal\", 1000)\nnormal_den_df[\"Label\"] = 0\nes_den_df = features_from_folder(\"/kaggle/working/denoised_data/Electrographic_Seizures\", 1000)\nes_den_df[\"Label\"] = 2\nvds_den_df = features_from_folder(\"/kaggle/working/denoised_data/Video_detected_Seizures_with_no_visual_change_over_EEG\", 1000)\nvds_den_df[\"Label\"] = 3\n\ntrain_data = pd.concat([cps_den_df, normal_den_df, es_den_df, vds_den_df], ignore_index=True)\ntrain_data = train_data.sample(frac=1).reset_index(drop=True)\nX_denoised = train_data.drop(\"Label\", axis=1)\ny_denoised = train_data[\"Label\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T11:44:36.385244Z","iopub.execute_input":"2025-01-19T11:44:36.385597Z","iopub.status.idle":"2025-01-19T11:45:13.604693Z","shell.execute_reply.started":"2025-01-19T11:44:36.385554Z","shell.execute_reply":"2025-01-19T11:45:13.603542Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"print(X_val.shape)\nprint(X_denoised.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T11:45:13.606694Z","iopub.execute_input":"2025-01-19T11:45:13.607062Z","iopub.status.idle":"2025-01-19T11:45:13.612247Z","shell.execute_reply.started":"2025-01-19T11:45:13.607034Z","shell.execute_reply":"2025-01-19T11:45:13.611345Z"}},"outputs":[{"name":"stdout","text":"(1403, 152)\n(5608, 152)\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"import xgboost as xgb\nmodel_xgb = xgb.XGBClassifier(\n    objective=\"multi:softprob\",  # For multi-class classification\n    eval_metric=\"mlogloss\",     # Log loss for evaluation\n    use_label_encoder=False,    # Suppress warning for label encoding\n    n_estimators=1000,           # Number of trees\n    max_depth=4,                # Depth of each tree\n    learning_rate=0.1           # Learning rate\n)\n\nmodel_xgb.fit(X_denoised, y_denoised)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T11:48:26.461921Z","iopub.execute_input":"2025-01-19T11:48:26.462300Z","iopub.status.idle":"2025-01-19T11:48:53.076087Z","shell.execute_reply.started":"2025-01-19T11:48:26.462274Z","shell.execute_reply":"2025-01-19T11:48:53.075254Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric='mlogloss',\n              feature_types=None, gamma=None, grow_policy=None,\n              importance_type=None, interaction_constraints=None,\n              learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n              max_cat_to_onehot=None, max_delta_step=None, max_depth=4,\n              max_leaves=None, min_child_weight=None, missing=nan,\n              monotone_constraints=None, multi_strategy=None, n_estimators=1000,\n              n_jobs=None, num_parallel_tree=None, objective='multi:softprob', ...)","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=&#x27;mlogloss&#x27;,\n              feature_types=None, gamma=None, grow_policy=None,\n              importance_type=None, interaction_constraints=None,\n              learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n              max_cat_to_onehot=None, max_delta_step=None, max_depth=4,\n              max_leaves=None, min_child_weight=None, missing=nan,\n              monotone_constraints=None, multi_strategy=None, n_estimators=1000,\n              n_jobs=None, num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=&#x27;mlogloss&#x27;,\n              feature_types=None, gamma=None, grow_policy=None,\n              importance_type=None, interaction_constraints=None,\n              learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n              max_cat_to_onehot=None, max_delta_step=None, max_depth=4,\n              max_leaves=None, min_child_weight=None, missing=nan,\n              monotone_constraints=None, multi_strategy=None, n_estimators=1000,\n              n_jobs=None, num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre></div></div></div></div></div>"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"y_pred = model_xgb.predict(X_val)\nprint(classification_report(y_val,y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T11:49:52.145649Z","iopub.execute_input":"2025-01-19T11:49:52.145959Z","iopub.status.idle":"2025-01-19T11:49:52.216393Z","shell.execute_reply.started":"2025-01-19T11:49:52.145933Z","shell.execute_reply":"2025-01-19T11:49:52.215314Z"}},"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.60      0.00      0.01       696\n           1       0.39      0.99      0.56       549\n           2       0.00      0.00      0.00       137\n           3       0.00      0.00      0.00        21\n\n    accuracy                           0.39      1403\n   macro avg       0.25      0.25      0.14      1403\nweighted avg       0.45      0.39      0.22      1403\n\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}